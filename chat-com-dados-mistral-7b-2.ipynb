{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd8fdd7-e0ff-4b98-b919-cd22b6bc1923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:26.358755Z",
     "iopub.status.busy": "2024-02-21T19:33:26.358456Z",
     "iopub.status.idle": "2024-02-21T19:33:27.573831Z",
     "shell.execute_reply": "2024-02-21T19:33:27.573401Z",
     "shell.execute_reply.started": "2024-02-21T19:33:26.358715Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d14191b-393f-43bb-9e5f-37a0240bc493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:27.574718Z",
     "iopub.status.busy": "2024-02-21T19:33:27.574563Z",
     "iopub.status.idle": "2024-02-21T19:33:27.578807Z",
     "shell.execute_reply": "2024-02-21T19:33:27.578522Z",
     "shell.execute_reply.started": "2024-02-21T19:33:27.574707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir=\"cache_dir\"\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74eac80-e888-49e3-95d9-20149dd2ba2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:27.579249Z",
     "iopub.status.busy": "2024-02-21T19:33:27.579154Z",
     "iopub.status.idle": "2024-02-21T19:33:27.658246Z",
     "shell.execute_reply": "2024-02-21T19:33:27.656522Z",
     "shell.execute_reply.started": "2024-02-21T19:33:27.579240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: 1\n",
      "GPU 0: NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus > 0:\n",
    "    print(f\"GPUs available: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"There is no GPU available. Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167eb948-647b-4c49-9fe1-6a8f2845b024",
   "metadata": {},
   "source": [
    "#### Leitura do arquivo e criação do splitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1cafe3-f4a4-4ef0-8ed9-ac39e3accd72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:27.660262Z",
     "iopub.status.busy": "2024-02-21T19:33:27.659815Z",
     "iopub.status.idle": "2024-02-21T19:33:27.667798Z",
     "shell.execute_reply": "2024-02-21T19:33:27.666447Z",
     "shell.execute_reply.started": "2024-02-21T19:33:27.660222Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('docs/nat.txt') as f:\n",
    "    clt = f.read()\n",
    "\n",
    "# Criação de um objeto RecursiveCharacterTextSplitter para dividir o texto em pedaços\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad2f45e-6475-4e0b-8ad9-7b7fb0a9d8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:27.671138Z",
     "iopub.status.busy": "2024-02-21T19:33:27.669892Z",
     "iopub.status.idle": "2024-02-21T19:33:27.678505Z",
     "shell.execute_reply": "2024-02-21T19:33:27.677530Z",
     "shell.execute_reply.started": "2024-02-21T19:33:27.671063Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents([clt])\n",
    "text_chunks = [doc.page_content for doc in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53798a5-5317-4fbc-ae1b-e06eca25e039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:27.680038Z",
     "iopub.status.busy": "2024-02-21T19:33:27.679573Z",
     "iopub.status.idle": "2024-02-21T19:33:28.426828Z",
     "shell.execute_reply": "2024-02-21T19:33:28.426423Z",
     "shell.execute_reply.started": "2024-02-21T19:33:27.680010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536,)\n"
     ]
    }
   ],
   "source": [
    "# Inicialize o modelo de embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Isso retornará uma lista de vetores\n",
    "embeddings = model.encode(text_chunks, convert_to_tensor=False)  \n",
    "\n",
    "# Adiciona zeros para estender cada vetor até a dimensão 1536\n",
    "extended_embeddings = np.array([np.pad(emb, (0, 1536 - len(emb)), 'constant') for emb in embeddings])\n",
    "print(extended_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1356940-9eb5-44fb-8ad0-e8ad77f1db06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:28.428031Z",
     "iopub.status.busy": "2024-02-21T19:33:28.427878Z",
     "iopub.status.idle": "2024-02-21T19:33:28.901979Z",
     "shell.execute_reply": "2024-02-21T19:33:28.901635Z",
     "shell.execute_reply.started": "2024-02-21T19:33:28.428020Z"
    }
   },
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "indexes = pc.list_indexes()\n",
    "index_name = 'natgpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24984a1b-802a-4b6a-9503-754eb0d1c75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:28.902547Z",
     "iopub.status.busy": "2024-02-21T19:33:28.902381Z",
     "iopub.status.idle": "2024-02-21T19:33:40.968678Z",
     "shell.execute_reply": "2024-02-21T19:33:40.967476Z",
     "shell.execute_reply.started": "2024-02-21T19:33:28.902537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index encontrada e apagada: natgpt\n",
      "Index natgpt criado\n"
     ]
    }
   ],
   "source": [
    "for i in indexes:\n",
    "    pc.delete_index(i['name'])\n",
    "    print('Index encontrada e apagada: ' + i['name'])\n",
    "\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(index_name, dimension=1536, metric='cosine', spec=PodSpec(environment=os.environ.get('PINECONE_ENV')))\n",
    "    print('Index '+index_name+' criado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c997369-fac0-4109-bbd6-560b3f81394d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:40.969958Z",
     "iopub.status.busy": "2024-02-21T19:33:40.969697Z",
     "iopub.status.idle": "2024-02-21T19:33:41.233091Z",
     "shell.execute_reply": "2024-02-21T19:33:41.231256Z",
     "shell.execute_reply.started": "2024-02-21T19:33:40.969935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Conecta na index criada\n",
    "pc_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123deabf-4206-4bdc-aa29-eb884a6e3a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:41.235693Z",
     "iopub.status.busy": "2024-02-21T19:33:41.235218Z",
     "iopub.status.idle": "2024-02-21T19:33:41.242585Z",
     "shell.execute_reply": "2024-02-21T19:33:41.242292Z",
     "shell.execute_reply.started": "2024-02-21T19:33:41.235647Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents_to_insert = []\n",
    "for i, embedding in enumerate(extended_embeddings):\n",
    "    doc_id = f\"{i}\"\n",
    "    documents_to_insert.append({\"id\": doc_id, \"values\": embedding.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "147f56bc-ca9e-4bdd-8270-3f9e275c22cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:33:41.243020Z",
     "iopub.status.busy": "2024-02-21T19:33:41.242924Z",
     "iopub.status.idle": "2024-02-21T19:34:02.448146Z",
     "shell.execute_reply": "2024-02-21T19:34:02.446822Z",
     "shell.execute_reply.started": "2024-02-21T19:33:41.243010Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insere os documentos na index do Pinecone\n",
    "pc_index.upsert(vectors=documents_to_insert)\n",
    "\n",
    "# Aguarda 20 segundos para dar tempo de atualizar a Index no Pinecone\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37e5b5-e7a1-419c-9ddf-b10e90225304",
   "metadata": {},
   "source": [
    "### Busca por similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1c3699-498d-4a3f-a203-b4e834ae6029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:02.450306Z",
     "iopub.status.busy": "2024-02-21T19:34:02.449842Z",
     "iopub.status.idle": "2024-02-21T19:34:02.595156Z",
     "shell.execute_reply": "2024-02-21T19:34:02.594519Z",
     "shell.execute_reply.started": "2024-02-21T19:34:02.450260Z"
    }
   },
   "outputs": [],
   "source": [
    "# SentenceTransformer para gerar o embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Inicialização do modelo para perguntas e respostas\n",
    "llm = InferenceClient(model=\"mistralai/Mistral-7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01c9c4a-e705-413f-a2ab-da28fff8f6b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:02.595954Z",
     "iopub.status.busy": "2024-02-21T19:34:02.595789Z",
     "iopub.status.idle": "2024-02-21T19:34:02.600750Z",
     "shell.execute_reply": "2024-02-21T19:34:02.600357Z",
     "shell.execute_reply.started": "2024-02-21T19:34:02.595937Z"
    }
   },
   "outputs": [],
   "source": [
    "def perguntar(prompt, top_k=3, debug=False):\n",
    "    \"\"\"\n",
    "    Recebe um prompt do usuário para fazer uma busca semântica, encontra os resultados\n",
    "    correspondentes no documento original e passa o resultado como contexto ao LLM\n",
    "\n",
    "    Parâmetros:\n",
    "    - prompt (str): Prompt do usuário. Também é usado para a busca semântica\n",
    "    - top_k (int): Quantidade de resultados mais semalhantes\n",
    "    - debug (bool): Retorna (ou não) o contexto passado ao LLM\n",
    "\n",
    "    Retorna:\n",
    "    - Tipo do retorno: A resposta do LLM com base na pergunta e contexto\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gerando o vetor de consulta\n",
    "    query_vector = model.encode(prompt, convert_to_tensor=False)\n",
    "    \n",
    "    # Adiciona zeros para estender cada vetor até a dimensão 1536\n",
    "    padding_length = 1536 - len(query_vector)\n",
    "    padded_vector = np.pad(query_vector, (0, padding_length), 'constant')\n",
    "    \n",
    "    query_vector_list = padded_vector.tolist()\n",
    "    query_result = pc_index.query(vector=query_vector_list, top_k=top_k)\n",
    "    \n",
    "    contexto = []\n",
    "    for index, match in enumerate(query_result.matches):\n",
    "        contexto.append(text_chunks[int(match.id)])\n",
    "\n",
    "    input_text = f\"[INST]Responda em Português: {prompt}.\\n\\nContexto: {contexto}[/INST]\"\n",
    "\n",
    "    response = llm.text_generation(\n",
    "        input_text,\n",
    "        temperature=0.2, \n",
    "        max_new_tokens=500,\n",
    "        top_k=30,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0\n",
    "    )\n",
    "\n",
    "    if(debug == True):\n",
    "        response = response + \"\\n\\n\\nDebug\\n---------------------------------\\n\" + str(contexto)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7e97a-8ac0-4d62-8dea-de29c57c184f",
   "metadata": {},
   "source": [
    "### Perguntas com base no contexto passado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e38e3c8-74b0-4440-ba33-beab2697bc56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:02.601559Z",
     "iopub.status.busy": "2024-02-21T19:34:02.601356Z",
     "iopub.status.idle": "2024-02-21T19:34:04.559461Z",
     "shell.execute_reply": "2024-02-21T19:34:04.557755Z",
     "shell.execute_reply.started": "2024-02-21T19:34:02.601545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Os coordenadores do NAT são Marcela Cristina Ozório como Coordenadora-Geral e Bernardo Fiterman Albano, como Coordenador-Adjunto.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Quem são os coordenadores do nat?', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ab25ff-2b9b-40b2-ba2b-73d64454542d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:04.561686Z",
     "iopub.status.busy": "2024-02-21T19:34:04.561221Z",
     "iopub.status.idle": "2024-02-21T19:34:05.478321Z",
     "shell.execute_reply": "2024-02-21T19:34:05.476351Z",
     "shell.execute_reply.started": "2024-02-21T19:34:04.561641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O site do NAT é https://nat.mpac.mp.br.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Qual o site do nat?', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "515f32f1-77c9-4805-a20f-12e3fae5866b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:05.481315Z",
     "iopub.status.busy": "2024-02-21T19:34:05.480600Z",
     "iopub.status.idle": "2024-02-21T19:34:10.359283Z",
     "shell.execute_reply": "2024-02-21T19:34:10.356908Z",
     "shell.execute_reply.started": "2024-02-21T19:34:05.481250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Os principais setores do NAT são:\n",
      "\n",
      "1. Coordenação de Desenvolvimento de Sistemas\n",
      "2. Observatório Criminal\n",
      "3. LAB\n",
      "4. Observatório de Políticas Públicas\n",
      "5. Técinco-Científica\n",
      "\n",
      "Os coordenadores do NAT são Marcela Cristina Ozório como Coordenadora-Geral e Bernardo Fiterman Albano, como Coordenador-Adjunto. Mais informações sobre o NAT podem ser encontradas no site https://nat.mpac.mp.br. Por meio do SIGEP, os membros solicitantes poderão acompanhar a tramitação do seu pedido de apoio no NAT, uma vez que ficarão registradas todas as etapas dos trabalhos executados e documentos anexados, de modo a facilitar a localização dos processos e posicionamento tanto do demandante quanto da Coordenação. O acesso para registro e acompanhamento de pedidos de apoio ao NAT pode ser feito por meio do endereço: https://sigep.mpac.mp.br.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Quais os principais setores do NAT', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c8770d-0b10-46f6-9a89-229c4a651293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:10.362429Z",
     "iopub.status.busy": "2024-02-21T19:34:10.361717Z",
     "iopub.status.idle": "2024-02-21T19:34:18.638261Z",
     "shell.execute_reply": "2024-02-21T19:34:18.636419Z",
     "shell.execute_reply.started": "2024-02-21T19:34:10.362376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O NAT (Núcleo de Apoio ao Processo de Pesquisa) é um órgão da Polícia Militar do Paraná (MPAC) responsável pela coordenação e suporte ao trabalho de pesquisa policial. O NAT tem vários setores, incluindo a Coordenação de Desenvolvimento de Sistemas, o Observatório Criminal, o LAB (Laboratório de Análises Biológicas), o Observatório de Políticas Públicas e a Técnica-Científica.\n",
      "\n",
      "Os coordenadores do NAT são Marcela Cristina Ozório e Bernardo Fiterman Albano. O acesso para registro e acompanhamento de pedidos de apoio ao NAT pode ser feito por meio do endereço: https://sigep.mpac.mp.br. Por meio do SIGEP (Sistema de Gestão Eletrônica de Processos), os membros solicitantes poderão acompanhar a tramitação do seu pedido de apoio no NAT, uma vez que ficarão registradas todas as etapas dos trabalhos executados e documentos anexados, de modo a facilitar a localização dos processos e o posicionamento tanto do demandante quanto da Coordenação. Mais informações sobre o NAT podem ser encontradas no site https://nat.mpac.mp.br.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Me da um resumo do NAT?', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38aed8bd-9ce4-4397-8acd-4872226fbb94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:18.641569Z",
     "iopub.status.busy": "2024-02-21T19:34:18.640753Z",
     "iopub.status.idle": "2024-02-21T19:34:23.303254Z",
     "shell.execute_reply": "2024-02-21T19:34:23.301314Z",
     "shell.execute_reply.started": "2024-02-21T19:34:18.641497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O Observatório de Políticas Públicas (OPP) é um projeto do Núcleo de Apoio Técnico-NAT que se propõe a monitorar os orçamentos públicos e a aplicação dos recursos, com o objetivo de verificar a consonância entre o que foi planejado com o executado, se o resultado almejado foi alcançado e promoveu a transformação social que era buscada. O OPP usará instrumentos formais como o Plano Plurianual, Lei de Diretrizes Orçamentárias e Lei Orçamentária Anual. O OPP produzirá e disponibilizará dados, informações e conhecimentos aos membros do MPAC, estabelecerá um sistema de informação confiável, flexível e escalável, e abrangerá as áreas da saúde, educação, meio ambiente, segurança pública e políticas de assistência social.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Me da um resumo do Observatório de Políticas Público', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e3fcc8-7cf7-47f7-b3a3-a4543ba2abfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:23.305857Z",
     "iopub.status.busy": "2024-02-21T19:34:23.305180Z",
     "iopub.status.idle": "2024-02-21T19:34:23.801077Z",
     "shell.execute_reply": "2024-02-21T19:34:23.799642Z",
     "shell.execute_reply.started": "2024-02-21T19:34:23.305805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O site do OPP (Observatório Político Público) é https://nat.mpac.mp.br/posts/category/observatorio-politicas-publicas/.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    perguntar(\n",
    "        prompt='Qual o site do OPP?', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5af0222f-19fa-4daf-8eca-9b9056e95bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-21T19:34:23.804300Z",
     "iopub.status.busy": "2024-02-21T19:34:23.803022Z",
     "iopub.status.idle": "2024-02-21T19:34:28.488669Z",
     "shell.execute_reply": "2024-02-21T19:34:28.487362Z",
     "shell.execute_reply.started": "2024-02-21T19:34:23.804236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Redes neurais artificiais são sistemas computacionais que tentam simular o funcionamento do cérebro humano. São utilizados em diversos campos, como a inteligência artificial, a saúde e a educação. Esses sistemas são capazes de aprender e adaptar-se ao seu ambiente, e podem ser utilizados para resolver problemas complexos, como a identificação de padrões em dados ou a tradução de idiomas.\n"
     ]
    }
   ],
   "source": [
    "# Pergunta com resposta totalmente fora do contexto\n",
    "print(\n",
    "    perguntar(\n",
    "        prompt='Me da um resumo, usando markdown, do que são redes neurais artificiais', top_k=3, debug=False\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
